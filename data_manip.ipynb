{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "from pathlib import Path\n",
    "from send2trash import send2trash\n",
    "from google_images_download import google_images_download\n",
    "import os\n",
    "\n",
    "x=os.getcwd()\n",
    "# Read the graph.\n",
    "with tf.io.gfile.GFile('frozen_inference_graph.pb', 'rb') as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_persons_and_save_crops(asana, graph_def, folder):\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        # Restore session\n",
    "        sess.graph.as_default()\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "        files = list(Path(folder).glob('*.jpg'))\n",
    "        files.extend(list(Path(folder).glob('*.png')))\n",
    "\n",
    "        for fid,fname in enumerate(files): \n",
    "            # Read and preprocess an image.\n",
    "            img = cv.imread(str(fname))\n",
    "            if(img is not None):\n",
    "                rows = img.shape[0]\n",
    "                cols = img.shape[1]\n",
    "                inp = cv.resize(img, (400, 400))\n",
    "                inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "                # Run the model\n",
    "                out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                                sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                                sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                                sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                               feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "\n",
    "                # Visualize detected bounding boxes.\n",
    "                num_detections = int(out[0][0])\n",
    "                #print(fname, num_detections)\n",
    "                for i in range(num_detections):\n",
    "                    classId = int(out[3][0][i])\n",
    "                    if(classId==1):\n",
    "                        score = float(out[1][0][i])\n",
    "                        bbox = [float(v) for v in out[2][0][i]]\n",
    "                        if score > 0.3:\n",
    "                            x = int(bbox[1] * cols)\n",
    "                            y = int(bbox[0] * rows)\n",
    "                            right = int(bbox[3] * cols)\n",
    "                            bottom = int(bbox[2] * rows)\n",
    "                            cv.imwrite(folder+str(fid)+'-'+str(i)+'.png', img[y:bottom, x:right])\n",
    "\n",
    "            try:\n",
    "                send2trash(str(fname))\n",
    "            except: pass    \n",
    "        print('cleaning '+asana+' done.')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning downdog done.\n"
     ]
    }
   ],
   "source": [
    "detect_persons_and_save_crops(\"downdog\", graph_def, x+'DATASET/TEST'+\"downdog\".lower()+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
